# ============================================================================
# OpenAI Configuration (for ChatGPT provider)
# ============================================================================
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-5-mini

# Alternative models:
# OPENAI_MODEL=gpt-5  # Better responses, more expensive
# OPENAI_MODEL=gpt-4o  # Fast and capable

# ============================================================================
# Ollama Configuration (for local inference)
# ============================================================================
# Ollama provides an OpenAI-compatible API endpoint for local model inference
# Supports Chat Completions API
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=ollama  # Ollama doesn't require a real API key (use "ollama")
OLLAMA_MODEL=qwen3:0.6b  # Change to your installed model

# Popular Ollama Models:
# OLLAMA_MODEL=qwen3:0.6b      # Qwen 3 0.6B (very fast, lightweight)
# OLLAMA_MODEL=llama3.2:3b     # Llama 3.2 3B (good balance)
# OLLAMA_MODEL=llama3.2        # Latest Llama 3.2 model
# OLLAMA_MODEL=llama3.1        # Llama 3.1 (larger, more capable)
# OLLAMA_MODEL=mistral         # Mistral 7B
# OLLAMA_MODEL=codellama       # Code-focused Llama
# OLLAMA_MODEL=phi3            # Microsoft Phi-3 (efficient)
# OLLAMA_MODEL=gemma2          # Google Gemma 2

# How to use Ollama:
# 1. Install Ollama: https://ollama.com/download
# 2. Pull a model: ollama pull llama3.2
# 3. Verify it's running: ollama list
# 4. Ollama automatically serves on http://localhost:11434
# 5. The OpenAI-compatible API is at http://localhost:11434/v1

# ============================================================================
# Redis Configuration (for conversation memory)
# ============================================================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=  # Leave empty if no password required

# Session Configuration
SESSION_TTL_SECONDS=3600  # Session expiration time (default: 1 hour)

# ============================================================================
# Quick Start Guide
# ============================================================================
# 1. Copy this file to .env: cp .env.example .env
# 2. Add your OpenAI API key to OPENAI_API_KEY
# 3. (Optional) Install and run Ollama for local inference
# 4. Start Redis: redis-server
# 5. Start backend: python backend/main.py
# 6. Open frontend: open frontend/index.html
